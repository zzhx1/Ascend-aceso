[2024-12-06 20:08:41,080] torch.distributed.run: [WARNING] 
[2024-12-06 20:08:41,080] torch.distributed.run: [WARNING] *****************************************
[2024-12-06 20:08:41,080] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-12-06 20:08:41,080] torch.distributed.run: [WARNING] *****************************************
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:299: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/workspace/RC4/ModelLink/megatron/training/arguments.py:944: DeprecationWarning: invalid escape sequence \ 
  '   --rampup-batch-size 16 8 300000 \ '
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Emitting ninja build file /root/.cache/torch_extensions/py39_cpu/adaptive_cp/build.ninja...
Building extension module adaptive_cp...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
ninja: no work to do.
Loading extension module adaptive_cp...
Loading extension module adaptive_cp...
Loading extension module adaptive_cp...
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Emitting ninja build file /root/.cache/torch_extensions/py39_cpu/adaptive_cp/build.ninja...
Building extension module adaptive_cp...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module adaptive_cp...
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Emitting ninja build file /root/.cache/torch_extensions/py39_cpu/adaptive_cp/build.ninja...
Building extension module adaptive_cp...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module adaptive_cp...
Loading extension module adaptive_cp...
Loading extension module adaptive_cp...
Loading extension module adaptive_cp...
world_size: 8
using world size: 8, context-parallel size: 1
--checkpoint-activations is no longer valid, use --recompute-activations, or, for more control, --recompute-granularity and --recompute-method.
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
Traceback (most recent call last):
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 228, in <module>
    main()
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 221, in main
    pretrain(train_valid_test_datasets_provider,
  File "/workspace/RC4/ModelLink/modellink/training/training.py", line 290, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/workspace/RC4/ModelLink/modellink/training/initialize.py", line 93, in initialize_megatron
    validate_args(args, args_defaults)####
  File "/workspace/RC4/ModelLink/modellink/training/arguments.py", line 965, in wrapper
    megatron_validate_args(args, defaults)
  File "/workspace/RC4/ModelLink/megatron/training/arguments.py", line 534, in validate_args
    validate_json_args(args)
  File "/workspace/RC4/ModelLink/megatron/training/json_arguments.py", line 60, in validate_json_args
    assert num_ops_total == args.num_layers * 2 + 2, f"num_ops_in_each_stage should sum to num_layers * 2 + 2: {num_ops_total} {args.num_layers}"
AssertionError: num_ops_in_each_stage should sum to num_layers * 2 + 2: 73 24
[ERROR] 2024-12-06-20:08:49 (PID:241896, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp60aoqz53'>
  _warnings.warn(warn_message, ResourceWarning)
world_size: 8
Traceback (most recent call last):
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 228, in <module>
    main()
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 221, in main
    pretrain(train_valid_test_datasets_provider,
  File "/workspace/RC4/ModelLink/modellink/training/training.py", line 290, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/workspace/RC4/ModelLink/modellink/training/initialize.py", line 93, in initialize_megatron
    validate_args(args, args_defaults)####
  File "/workspace/RC4/ModelLink/modellink/training/arguments.py", line 965, in wrapper
    megatron_validate_args(args, defaults)
  File "/workspace/RC4/ModelLink/megatron/training/arguments.py", line 534, in validate_args
    validate_json_args(args)
  File "/workspace/RC4/ModelLink/megatron/training/json_arguments.py", line 60, in validate_json_args
    assert num_ops_total == args.num_layers * 2 + 2, f"num_ops_in_each_stage should sum to num_layers * 2 + 2: {num_ops_total} {args.num_layers}"
AssertionError: num_ops_in_each_stage should sum to num_layers * 2 + 2: 73 24
[ERROR] 2024-12-06-20:08:49 (PID:241899, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmphkulbd9j'>
  _warnings.warn(warn_message, ResourceWarning)
world_size: 8
Traceback (most recent call last):
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 228, in <module>
    main()
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 221, in main
    pretrain(train_valid_test_datasets_provider,
  File "/workspace/RC4/ModelLink/modellink/training/training.py", line 290, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/workspace/RC4/ModelLink/modellink/training/initialize.py", line 93, in initialize_megatron
    validate_args(args, args_defaults)####
  File "/workspace/RC4/ModelLink/modellink/training/arguments.py", line 965, in wrapper
    megatron_validate_args(args, defaults)
  File "/workspace/RC4/ModelLink/megatron/training/arguments.py", line 534, in validate_args
    validate_json_args(args)
  File "/workspace/RC4/ModelLink/megatron/training/json_arguments.py", line 60, in validate_json_args
    assert num_ops_total == args.num_layers * 2 + 2, f"num_ops_in_each_stage should sum to num_layers * 2 + 2: {num_ops_total} {args.num_layers}"
AssertionError: num_ops_in_each_stage should sum to num_layers * 2 + 2: 73 24
[ERROR] 2024-12-06-20:08:49 (PID:241900, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpii0th9oc'>
  _warnings.warn(warn_message, ResourceWarning)
world_size: 8
Traceback (most recent call last):
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 228, in <module>
    main()
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 221, in main
    pretrain(train_valid_test_datasets_provider,
  File "/workspace/RC4/ModelLink/modellink/training/training.py", line 290, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/workspace/RC4/ModelLink/modellink/training/initialize.py", line 93, in initialize_megatron
    validate_args(args, args_defaults)####
  File "/workspace/RC4/ModelLink/modellink/training/arguments.py", line 965, in wrapper
    megatron_validate_args(args, defaults)
  File "/workspace/RC4/ModelLink/megatron/training/arguments.py", line 534, in validate_args
    validate_json_args(args)
  File "/workspace/RC4/ModelLink/megatron/training/json_arguments.py", line 60, in validate_json_args
    assert num_ops_total == args.num_layers * 2 + 2, f"num_ops_in_each_stage should sum to num_layers * 2 + 2: {num_ops_total} {args.num_layers}"
AssertionError: num_ops_in_each_stage should sum to num_layers * 2 + 2: 73 24
[ERROR] 2024-12-06-20:08:50 (PID:241902, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpttqqd3lx'>
  _warnings.warn(warn_message, ResourceWarning)
world_size: 8
Traceback (most recent call last):
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 228, in <module>
    main()
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 221, in main
    pretrain(train_valid_test_datasets_provider,
  File "/workspace/RC4/ModelLink/modellink/training/training.py", line 290, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/workspace/RC4/ModelLink/modellink/training/initialize.py", line 93, in initialize_megatron
    validate_args(args, args_defaults)####
  File "/workspace/RC4/ModelLink/modellink/training/arguments.py", line 965, in wrapper
    megatron_validate_args(args, defaults)
  File "/workspace/RC4/ModelLink/megatron/training/arguments.py", line 534, in validate_args
    validate_json_args(args)
  File "/workspace/RC4/ModelLink/megatron/training/json_arguments.py", line 60, in validate_json_args
    assert num_ops_total == args.num_layers * 2 + 2, f"num_ops_in_each_stage should sum to num_layers * 2 + 2: {num_ops_total} {args.num_layers}"
AssertionError: num_ops_in_each_stage should sum to num_layers * 2 + 2: 73 24
[ERROR] 2024-12-06-20:08:50 (PID:241897, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp1ttgz16a'>
  _warnings.warn(warn_message, ResourceWarning)
world_size: 8
Traceback (most recent call last):
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 228, in <module>
    main()
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 221, in main
    pretrain(train_valid_test_datasets_provider,
  File "/workspace/RC4/ModelLink/modellink/training/training.py", line 290, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/workspace/RC4/ModelLink/modellink/training/initialize.py", line 93, in initialize_megatron
    validate_args(args, args_defaults)####
  File "/workspace/RC4/ModelLink/modellink/training/arguments.py", line 965, in wrapper
    megatron_validate_args(args, defaults)
  File "/workspace/RC4/ModelLink/megatron/training/arguments.py", line 534, in validate_args
    validate_json_args(args)
  File "/workspace/RC4/ModelLink/megatron/training/json_arguments.py", line 60, in validate_json_args
    assert num_ops_total == args.num_layers * 2 + 2, f"num_ops_in_each_stage should sum to num_layers * 2 + 2: {num_ops_total} {args.num_layers}"
AssertionError: num_ops_in_each_stage should sum to num_layers * 2 + 2: 73 24
[ERROR] 2024-12-06-20:08:50 (PID:241898, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpm657myou'>
  _warnings.warn(warn_message, ResourceWarning)
world_size: 8
Traceback (most recent call last):
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 228, in <module>
    main()
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 221, in main
    pretrain(train_valid_test_datasets_provider,
  File "/workspace/RC4/ModelLink/modellink/training/training.py", line 290, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/workspace/RC4/ModelLink/modellink/training/initialize.py", line 93, in initialize_megatron
    validate_args(args, args_defaults)####
  File "/workspace/RC4/ModelLink/modellink/training/arguments.py", line 965, in wrapper
world_size: 8    megatron_validate_args(args, defaults)

  File "/workspace/RC4/ModelLink/megatron/training/arguments.py", line 534, in validate_args
    validate_json_args(args)
  File "/workspace/RC4/ModelLink/megatron/training/json_arguments.py", line 60, in validate_json_args
    assert num_ops_total == args.num_layers * 2 + 2, f"num_ops_in_each_stage should sum to num_layers * 2 + 2: {num_ops_total} {args.num_layers}"
AssertionError: num_ops_in_each_stage should sum to num_layers * 2 + 2: 73 24
Traceback (most recent call last):
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 228, in <module>
    main()
  File "/workspace/RC4/ModelLink/pretrain_gpt.py", line 221, in main
    pretrain(train_valid_test_datasets_provider,
  File "/workspace/RC4/ModelLink/modellink/training/training.py", line 290, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/workspace/RC4/ModelLink/modellink/training/initialize.py", line 93, in initialize_megatron
    validate_args(args, args_defaults)####
  File "/workspace/RC4/ModelLink/modellink/training/arguments.py", line 965, in wrapper
[ERROR] 2024-12-06-20:08:50 (PID:241901, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
    megatron_validate_args(args, defaults)
  File "/workspace/RC4/ModelLink/megatron/training/arguments.py", line 534, in validate_args
    validate_json_args(args)
  File "/workspace/RC4/ModelLink/megatron/training/json_arguments.py", line 60, in validate_json_args
    assert num_ops_total == args.num_layers * 2 + 2, f"num_ops_in_each_stage should sum to num_layers * 2 + 2: {num_ops_total} {args.num_layers}"
AssertionError: num_ops_in_each_stage should sum to num_layers * 2 + 2: 73 24
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpbtvlnuie'>
  _warnings.warn(warn_message, ResourceWarning)
[ERROR] 2024-12-06-20:08:50 (PID:241903, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpnxc7_m4_'>
  _warnings.warn(warn_message, ResourceWarning)
[2024-12-06 20:08:51,156] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 241897 closing signal SIGTERM
[2024-12-06 20:08:51,157] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 241898 closing signal SIGTERM
[2024-12-06 20:08:51,157] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 241900 closing signal SIGTERM
[2024-12-06 20:08:51,157] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 241901 closing signal SIGTERM
[2024-12-06 20:08:51,158] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 241902 closing signal SIGTERM
[2024-12-06 20:08:51,158] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 241903 closing signal SIGTERM
[2024-12-06 20:08:52,587] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 241896) of binary: /home/ma-user/anaconda3/envs/PyTorch-2.1.0/bin/python3.9
