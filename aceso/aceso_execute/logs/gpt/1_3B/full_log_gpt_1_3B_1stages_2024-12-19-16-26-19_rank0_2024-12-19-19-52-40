[2024-12-19 19:52:43,111] torch.distributed.run: [WARNING] 
[2024-12-19 19:52:43,111] torch.distributed.run: [WARNING] *****************************************
[2024-12-19 19:52:43,111] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-12-19 19:52:43,111] torch.distributed.run: [WARNING] *****************************************
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:299: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Emitting ninja build file /root/.cache/torch_extensions/py39_cpu/adaptive_cp/build.ninja...
Building extension module adaptive_cp...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
ninja: no work to do.
Loading extension module adaptive_cp...
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Traceback (most recent call last):
  File "/workspace/Ascend-aceso/aceso/aceso_execute/../../pretrain_gpt.py", line 9, in <module>
    from modellink import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/__init__.py", line 16, in <module>
    from modellink.tasks import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 635, in <module>
    MegatronAdaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 37, in execute
    adaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 127, in execute
    self.patch_core_models()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 165, in patch_core_models
    from ..training.utils import get_batch_on_this_cp_rank, get_batch_on_this_tp_rank, get_device_wrapper
  File "/workspace/Ascend-aceso/modellink/training/__init__.py", line 16, in <module>
    from .training import (get_model_wrapper, is_profile_enabled, get_profiler, setup_model_and_optimizer_wrapper,
  File "/workspace/Ascend-aceso/modellink/training/training.py", line 659
    print(f"{"-"*10}\t\tAverage Iteration Time: {iter_total_time / iter_count}\t\t{"-"*10}")
              ^
SyntaxError: f-string: expecting '}'
[ERROR] 2024-12-19-19:52:50 (PID:708274, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp3cdrfj_q'>
  _warnings.warn(warn_message, ResourceWarning)
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
Emitting ninja build file /root/.cache/torch_extensions/py39_cpu/adaptive_cp/build.ninja...
Building extension module adaptive_cp...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /root/.cache/torch_extensions/py39_cpu as PyTorch extensions root...
ninja: no work to do.
Loading extension module adaptive_cp...
Loading extension module adaptive_cp...
Traceback (most recent call last):
  File "/workspace/Ascend-aceso/aceso/aceso_execute/../../pretrain_gpt.py", line 9, in <module>
    from modellink import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/__init__.py", line 16, in <module>
    from modellink.tasks import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 635, in <module>
    MegatronAdaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 37, in execute
    adaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 127, in execute
    self.patch_core_models()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 165, in patch_core_models
    from ..training.utils import get_batch_on_this_cp_rank, get_batch_on_this_tp_rank, get_device_wrapper
  File "/workspace/Ascend-aceso/modellink/training/__init__.py", line 16, in <module>
    from .training import (get_model_wrapper, is_profile_enabled, get_profiler, setup_model_and_optimizer_wrapper,
  File "/workspace/Ascend-aceso/modellink/training/training.py", line 659
    print(f"{"-"*10}\t\tAverage Iteration Time: {iter_total_time / iter_count}\t\t{"-"*10}")
              ^
SyntaxError: f-string: expecting '}'
[ERROR] 2024-12-19-19:52:51 (PID:708276, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpr8pkka1z'>
  _warnings.warn(warn_message, ResourceWarning)
Traceback (most recent call last):
  File "/workspace/Ascend-aceso/aceso/aceso_execute/../../pretrain_gpt.py", line 9, in <module>
    from modellink import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/__init__.py", line 16, in <module>
    from modellink.tasks import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 635, in <module>
    MegatronAdaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 37, in execute
    adaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 127, in execute
    self.patch_core_models()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 165, in patch_core_models
    from ..training.utils import get_batch_on_this_cp_rank, get_batch_on_this_tp_rank, get_device_wrapper
  File "/workspace/Ascend-aceso/modellink/training/__init__.py", line 16, in <module>
    from .training import (get_model_wrapper, is_profile_enabled, get_profiler, setup_model_and_optimizer_wrapper,
  File "/workspace/Ascend-aceso/modellink/training/training.py", line 659
    print(f"{"-"*10}\t\tAverage Iteration Time: {iter_total_time / iter_count}\t\t{"-"*10}")
              ^
SyntaxError: f-string: expecting '}'
[ERROR] 2024-12-19-19:52:51 (PID:708279, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpxcxzhbah'>
  _warnings.warn(warn_message, ResourceWarning)
Loading extension module adaptive_cp...
Loading extension module adaptive_cp...
Traceback (most recent call last):
  File "/workspace/Ascend-aceso/aceso/aceso_execute/../../pretrain_gpt.py", line 9, in <module>
    from modellink import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/__init__.py", line 16, in <module>
    from modellink.tasks import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 635, in <module>
    MegatronAdaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 37, in execute
    adaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 127, in execute
    self.patch_core_models()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 165, in patch_core_models
    from ..training.utils import get_batch_on_this_cp_rank, get_batch_on_this_tp_rank, get_device_wrapper
  File "/workspace/Ascend-aceso/modellink/training/__init__.py", line 16, in <module>
    from .training import (get_model_wrapper, is_profile_enabled, get_profiler, setup_model_and_optimizer_wrapper,
  File "/workspace/Ascend-aceso/modellink/training/training.py", line 659
    print(f"{"-"*10}\t\tAverage Iteration Time: {iter_total_time / iter_count}\t\t{"-"*10}")
              ^
SyntaxError: f-string: expecting '}'
[ERROR] 2024-12-19-19:52:51 (PID:708278, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpqd2eq4ud'>
  _warnings.warn(warn_message, ResourceWarning)
Traceback (most recent call last):
  File "/workspace/Ascend-aceso/aceso/aceso_execute/../../pretrain_gpt.py", line 9, in <module>
    from modellink import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/__init__.py", line 16, in <module>
    from modellink.tasks import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 635, in <module>
    MegatronAdaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 37, in execute
    adaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 127, in execute
    self.patch_core_models()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 165, in patch_core_models
    from ..training.utils import get_batch_on_this_cp_rank, get_batch_on_this_tp_rank, get_device_wrapper
  File "/workspace/Ascend-aceso/modellink/training/__init__.py", line 16, in <module>
    from .training import (get_model_wrapper, is_profile_enabled, get_profiler, setup_model_and_optimizer_wrapper,
  File "/workspace/Ascend-aceso/modellink/training/training.py", line 659
    print(f"{"-"*10}\t\tAverage Iteration Time: {iter_total_time / iter_count}\t\t{"-"*10}")
              ^
SyntaxError: f-string: expecting '}'
[ERROR] 2024-12-19-19:52:51 (PID:708281, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp96g01t59'>
  _warnings.warn(warn_message, ResourceWarning)
Loading extension module adaptive_cp...
Loading extension module adaptive_cp...
Loading extension module adaptive_cp...
Traceback (most recent call last):
  File "/workspace/Ascend-aceso/aceso/aceso_execute/../../pretrain_gpt.py", line 9, in <module>
    from modellink import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/__init__.py", line 16, in <module>
    from modellink.tasks import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 635, in <module>
    MegatronAdaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 37, in execute
    adaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 127, in execute
    self.patch_core_models()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 165, in patch_core_models
    from ..training.utils import get_batch_on_this_cp_rank, get_batch_on_this_tp_rank, get_device_wrapper
  File "/workspace/Ascend-aceso/modellink/training/__init__.py", line 16, in <module>
    from .training import (get_model_wrapper, is_profile_enabled, get_profiler, setup_model_and_optimizer_wrapper,
  File "/workspace/Ascend-aceso/modellink/training/training.py", line 659
    print(f"{"-"*10}\t\tAverage Iteration Time: {iter_total_time / iter_count}\t\t{"-"*10}")
              ^
SyntaxError: f-string: expecting '}'
[ERROR] 2024-12-19-19:52:51 (PID:708277, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp35en11e9'>
  _warnings.warn(warn_message, ResourceWarning)
Traceback (most recent call last):
  File "/workspace/Ascend-aceso/aceso/aceso_execute/../../pretrain_gpt.py", line 9, in <module>
    from modellink import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/__init__.py", line 16, in <module>
    from modellink.tasks import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 635, in <module>
    MegatronAdaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 37, in execute
    adaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 127, in execute
    self.patch_core_models()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 165, in patch_core_models
    from ..training.utils import get_batch_on_this_cp_rank, get_batch_on_this_tp_rank, get_device_wrapper
  File "/workspace/Ascend-aceso/modellink/training/__init__.py", line 16, in <module>
    from .training import (get_model_wrapper, is_profile_enabled, get_profiler, setup_model_and_optimizer_wrapper,
  File "/workspace/Ascend-aceso/modellink/training/training.py", line 659
    print(f"{"-"*10}\t\tAverage Iteration Time: {iter_total_time / iter_count}\t\t{"-"*10}")
              ^
SyntaxError: f-string: expecting '}'
Traceback (most recent call last):
  File "/workspace/Ascend-aceso/aceso/aceso_execute/../../pretrain_gpt.py", line 9, in <module>
[ERROR] 2024-12-19-19:52:51 (PID:708280, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
    from modellink import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/__init__.py", line 16, in <module>
    from modellink.tasks import megatron_adaptor
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 635, in <module>
    MegatronAdaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 37, in execute
    adaptation.execute()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 127, in execute
    self.patch_core_models()
  File "/workspace/Ascend-aceso/modellink/tasks/megatron_adaptor.py", line 165, in patch_core_models
    from ..training.utils import get_batch_on_this_cp_rank, get_batch_on_this_tp_rank, get_device_wrapper
  File "/workspace/Ascend-aceso/modellink/training/__init__.py", line 16, in <module>
    from .training import (get_model_wrapper, is_profile_enabled, get_profiler, setup_model_and_optimizer_wrapper,
  File "/workspace/Ascend-aceso/modellink/training/training.py", line 659
    print(f"{"-"*10}\t\tAverage Iteration Time: {iter_total_time / iter_count}\t\t{"-"*10}")
              ^
SyntaxError: f-string: expecting '}'
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmptibrm45q'>
  _warnings.warn(warn_message, ResourceWarning)
[ERROR] 2024-12-19-19:52:51 (PID:708275, Device:-1, RankID:-1) ERR99999 UNKNOWN application exception
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/tempfile.py:821: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpyjekx8cm'>
  _warnings.warn(warn_message, ResourceWarning)
[2024-12-19 19:52:53,191] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 708274) of binary: /home/ma-user/anaconda3/envs/PyTorch-2.1.0/bin/python3.9
